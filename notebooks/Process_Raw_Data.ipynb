{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "import PIL\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Set up processed output directories\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The root repository directory is set for my laptop!\n",
    "#       Users may need to update the path below before running the code.\n",
    "\n",
    "# set path for repository root directory\n",
    "repo_root_path = \"C:/Users/Jonathon.Poage/Desktop/Springboard/Git_and_Github/Capstone_2_repo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for processed data directory\n",
    "processed_data_path = repo_root_path + \"data/processed/\"\n",
    "\n",
    "# make train validation test subdirectories\n",
    "train_dir = processed_data_path + \"train_data/\"\n",
    "validation_dir = processed_data_path + \"validation_data/\"\n",
    "test_dir = processed_data_path + \"test_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if processed train validation test subdirectories exist, remove them\n",
    "if os.path.exists(train_dir):\n",
    "    shutil.rmtree(train_dir)\n",
    "    \n",
    "if os.path.exists(validation_dir):\n",
    "    shutil.rmtree(validation_dir)\n",
    "    \n",
    "if os.path.exists(test_dir):\n",
    "    shutil.rmtree(test_dir)\n",
    "    \n",
    "# make new processed train validation test subdirectories\n",
    "os.makedirs(train_dir)\n",
    "os.makedirs(validation_dir)\n",
    "os.makedirs(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Separate image files into train, validation, and test sets\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path for raw data directory\n",
    "raw_data_path = repo_root_path + \"data/raw/\"\n",
    "\n",
    "# load raw test data files\n",
    "raw_test_files = glob(raw_data_path + \"chest_xray/test/*/*.jpeg\")\n",
    "\n",
    "# load raw train data files\n",
    "raw_train_files = glob(raw_data_path + \"chest_xray/train/*/*.jpeg\")\n",
    "\n",
    "# separate raw train files by class\n",
    "raw_train_bacteria_files = [fn for fn in raw_train_files if 'BACTERIA' in fn]\n",
    "raw_train_virus_files = [fn for fn in raw_train_files if 'VIRUS' in fn]\n",
    "raw_train_normal_files = [fn for fn in raw_train_files if 'NORMAL' in fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of files in test set\n",
    "test_files = raw_test_files\n",
    "\n",
    "# randomly sample image files for validation set\n",
    "bacteria_val_files = np.random.choice(raw_train_bacteria_files,\n",
    "                                      size=len(raw_train_bacteria_files) // 4,\n",
    "                                      replace=False).tolist()\n",
    "\n",
    "virus_val_files = np.random.choice(raw_train_virus_files,\n",
    "                                   size=len(raw_train_virus_files) // 4,\n",
    "                                   replace=False).tolist()\n",
    "\n",
    "normal_val_files = np.random.choice(raw_train_normal_files,\n",
    "                                    size=len(raw_train_normal_files) // 4,\n",
    "                                    replace=False).tolist()\n",
    "\n",
    "# make lists of files for train set\n",
    "bacteria_train_files = list(set(raw_train_bacteria_files) - set(bacteria_val_files))\n",
    "virus_train_files = list(set(raw_train_virus_files) - set(virus_val_files))\n",
    "normal_train_files = list(set(raw_train_normal_files) - set(normal_val_files))\n",
    "\n",
    "# concatenate the lists for the train and validation sets\n",
    "train_files = bacteria_train_files + virus_train_files + normal_train_files\n",
    "validation_files = bacteria_val_files + virus_val_files + normal_val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Copy image files into train, validation, test subdirectories\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the files to the processed data subdirectories\n",
    "for fn in train_files:\n",
    "    shutil.copy(fn, train_dir + \"image_files/\")\n",
    "    \n",
    "for fn in validation_files:\n",
    "    shutil.copy(fn, validation_dir + \"image_files/\")\n",
    "    \n",
    "for fn in test_files:\n",
    "    shutil.copy(fn, test_dir + \"image_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I have validated everythign above this cell!!\n",
    "# TO DO: VALIDATE EVERYTHING BELOW THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Process image file data into dataframes\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get class from filename\n",
    "def get_class_from_filename(filename):\n",
    "    \"\"\"Takes a string with the base name of a filepath as input.\n",
    "    returns the class as a string.\"\"\"\n",
    "    \n",
    "    if 'NORMAL' in filename:\n",
    "        str_class = 'normal'\n",
    "    elif 'BACTERIA' in filename:\n",
    "        str_class = 'bacterial_pneumonia'\n",
    "    elif 'VIRUS' in filename:\n",
    "        str_class = 'viral_pneumonia'\n",
    "    else:\n",
    "        raise Exception('Filename not valid!  Class not found.')\n",
    "    \n",
    "    return str_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe with train data\n",
    "def df_from_filepath_list(filepath_list, img_size):\n",
    "    \"\"\"Take a list of filepath strings and a tuple of ints\n",
    "    with image pixel dimensions as input.\n",
    "    Returns a dataframe with the base path, class,\n",
    "    and numpy pixel array for each filepath.\"\"\"\n",
    "    \n",
    "    list_of_tuples = []\n",
    "    \n",
    "    for fp in filepath_list:\n",
    "        f_name = os.path.basename(fp)\n",
    "        f_class = get_class_from_filename(f_name)\n",
    "        pixel_array = img_to_array(load_img(fp, target_size=img_size))\n",
    "        list_of_tuples.append((f_name, f_class, pixel_array))\n",
    "        \n",
    "    return pd.DataFrame(list_of_tuples,\n",
    "                        columns=['Image_file_base_path', 'class', 'pixel_array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the image size\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# create the train validation test dataframes\n",
    "df_train = df_from_filepath_list(train_files, IMG_SIZE)\n",
    "df_validation = df_from_filepath_list(validation_files, IMG_SIZE)\n",
    "df_test = df_from_filepath_list(test_files, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one hot encoding for the classes\n",
    "df_train = df_train.join(pd.get_dummies(df_train['class']))\n",
    "df_validation = df_validation.join(pd.get_dummies(df_validation['class']))\n",
    "df_test = df_test.join(pd.get_dummies(df_test['class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Save processed data to disk\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframes to pickle files\n",
    "df_validation.to_pickle(validation_dir + \"validation_data.pickle\")\n",
    "df_test.to_pickle(test_dir + \"test_data.pickle\")\n",
    "\n",
    "# NOTE: df_train.to_pickle() kept crashing, so I'm saving it in parts\n",
    "df_train.iloc[0:1300].to_pickle(train_dir + 'train_data_part1.pickle')\n",
    "df_train.iloc[1300:2600].to_pickle(train_dir + 'train_data_part2.pickle')\n",
    "df_train.iloc[2600:].to_pickle(train_dir + 'train_data_part3.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
